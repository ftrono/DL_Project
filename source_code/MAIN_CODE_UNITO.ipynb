{"cells":[{"cell_type":"markdown","metadata":{"id":"sg9k_BBLMS93"},"source":["# **Deep Learning Project**\n","\n","**Eliana Battisti - Davide Dalla Stella - Francesco Trono**\n","\n","*University of Trento*\n","\n","A.Y. 2020/2021 - Deep Learning Course"]},{"cell_type":"markdown","metadata":{},"source":["Click to open & run in Colab:\n","\n","\n","[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ftrono/DL_Project/blob/main/source_code/MAIN_CODE_UNITO.ipynb)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6857,"status":"ok","timestamp":1639663374869,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"EbSOUkq2cmbH","outputId":"ebbd3725-5f5a-4621-819d-6d7c57154eef"},"outputs":[],"source":["#!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html -U"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1639663374871,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"0KPK4NeNMS4N"},"outputs":[],"source":["import os\n","import shutil\n","import csv\n","import torch\n","import torchvision\n","import torch.nn.functional as F\n","import torchvision.transforms as T\n","from torch.utils.data import Dataset, DataLoader\n","import collections\n","from torch.utils.tensorboard import SummaryWriter\n","from PIL import Image\n","from google.colab import drive\n","from sklearn.preprocessing import MultiLabelBinarizer"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":1661,"status":"ok","timestamp":1639663376523,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"iE1i5OzdPfl3"},"outputs":[],"source":["#Set FLAG to 1 only if you want to create the Dataset from 0\n","FLAG = 1\n","\n","if os.path.isdir(\"/content/Dataset\") and FLAG == 1:\n","  shutil.rmtree(\"/content/Dataset\")"]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":12,"status":"ok","timestamp":1639663376524,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"GYBV9XAnR3Qt"},"outputs":[],"source":["#Global variables:\n","num_classifiers = 12\n","device = \"cuda:0\"\n","#device = \"cpu\"\n","localpath = \"/content/Dataset/\""]},{"cell_type":"markdown","metadata":{"id":"upUeC5MRMz5N"},"source":["**1) Dataset preparation**"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2057,"status":"ok","timestamp":1639663378571,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"sY78jNMgL3se","outputId":"846f402f-6385-44bc-9a30-f198a57704a0"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}],"source":["#Mounting Google Drive:\n","drive.mount('/content/drive/', force_remount = False)\n","\n","#Main path to dataset:\n","dspath = \"/content/drive/My Drive/DL_Project_Team/DL_Project/Dataset\""]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4427,"status":"ok","timestamp":1639663382991,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"yaxBDddWGIBK","outputId":"a31cf003-2096-4264-bd38-6699a71107a3"},"outputs":[{"name":"stdout","output_type":"stream","text":["Unzipped.\n"]}],"source":["#copy train files in local\n","from google.colab import files\n","!mkdir \"Dataset\"\n","!unzip \"/content/drive/MyDrive/DL_Project_Team/DL_Project/Dataset/dataset.zip\" -d \"/content/Dataset/\" >/dev/null\n","print(\"Unzipped.\")\n","\n"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":27,"status":"ok","timestamp":1639663382993,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"HljEsNz5PND1"},"outputs":[],"source":["#Parte training split (train / validation e validation_query, test):\n","#Creare 2 folder diverse, una per Train e l'altra per Validation, entrambe partendo dalla folder Train esistente.\n","\n","#Scaricare dataset su macchina locale (mantieni struttura sottofolder) (esempio -> https://colab.research.google.com/drive/1oOKXtUUaACKG_P1SZO-PpfygP5_12dX7#scrollTo=h8gyumMki8A6 )\n","#Parte training split (train / validation):\n","#Creare 2 folder diverse, una per Train e l'altra per Validation, entrambe partendo dalla folder Train esistente.\n","\n","#Seguire indicazioni nel TO-DOs. Lavorare tramite bash in locale:\n","#Scaricare dataset su macchina locale (mantieni struttura sottofolder) (esempio -> https://colab.research.google.com/drive/1oOKXtUUaACKG_P1SZO-PpfygP5_12dX7#scrollTo=h8gyumMki8A6 )\n","\n","def dataset_preparation(img_root, csv_dir):\n","\n","    # PART 1\n","\n","    # directory che porta all'interno della cartella validation\n","    validation_dir = img_root+\"validation\"\n","    train_dir = img_root+\"train\"  # directory che porta all'interno della cartella train\n","    n_id = -1\n","    # contatore per sapere quanti id di persone ho. Parte da -1 così tolgo la riga che contiene solo la legenda\n","\n","    # per evitare di rischiare di ripetere lo spostamento di immagini ad ogni esecuzione del programma lo\n","    # spostamento di immagini lo eseguo solo nel caso in cui la cartella non esista così da essere sicuro di\n","    # spostare le immagini solo alla prima esecuzione\n","    # controllo se esiste la cartella validation. Se no allora la creo\n","    if not os.path.isdir(validation_dir):\n","        os.mkdir(validation_dir)\n","        # il csv_file mi serve per sapere quanti id di persone ho\n","        with open(csv_dir) as annotations_train:  # conto il numero di id con un ciclo for\n","            print(annotations_train)\n","            # sommo il numero di righe all'interno del csv file\n","            n_id += sum(1 for row in annotations_train)\n","\n","        to_move = n_id // 4\n","\n","        print(\"Moving 25% of training files in validation\")\n","        # loop che sposta le foto di un quarto delle persone contenute nella cartella\n","        for i in range(0, to_move):\n","            # metodo per ottenere la lista coi nomi di tutti i file all'interno di una dir\n","            # ad ogni ciclo aggiorno la lista così non rischio di spostare file già spostati\n","            train_list = os.listdir(train_dir)\n","            # prendo il nome della prima immagine nella lista e mi prendo solo le prime 4 lettere che indicano l'id della persona\n","            id_to_move = train_list[0][0:4]\n","            #print(\"id to move: \", id_to_move)\n","            for files in train_list:  # scorro tutta la lista dei file\n","                # controllo se i file iniziano con l'id selezionato\n","                if files.startswith(id_to_move):\n","                    # se l'id corrisponde lo sposto\n","                    shutil.move(train_dir+\"/\"+files, validation_dir+\"/\"+files)\n","                    #print(\"Moved: \",train_dir+\"/\"+files, \"in: \",validation_dir+\"/\"+files)\n","\n","            # just a check to see if I did something  wrong and there are duplicates in the two folders\n","            '''train_list = os.listdir(train_dir) \n","      val_list = os.listdir(validation_dir) \n","      if files in train_list and files in val_list:\n","        file_train = train_list[train_list.index(files)]\n","        file_val = val_list[val_list.index(files)]\n","        print(\"Train file: \"file_train,\"\\nVal file: \",file_val,\"\\n\\n\")'''\n","            # end check\n","\n","            # just a check to see if I missed to move an image that starts with a certain index\n","            '''train_list = os.listdir(train_dir) \n","      val_list = os.listdir(validation_dir) \n","      for train_file in train_dir:\n","        id_train = train_file[0][0:4]\n","        for val_file in val_list:\n","          if val_file.startswith(id_train):\n","            print(\"Train file: \",train_file,\"\\nVal file: \",val_file,\"\\n\\n\")'''\n","            # end check\n","\n","        print(\"Training files moved to validation\")\n","    else:\n","        print(\"Validation already created.\")\n","\n","    # PART 2\n","\n","    '''validation_queries_dir = img_root+ \"/validation_queries\"\n","  test_dir = img_root + \"/test\"\n","\n","  if not os.path.isdir(validation_queries_dir): #Se una delle cartelle non esiste allora assumo che non ne esista nessuna\n","    if not os.path.isdir(test_dir):\n","      os.mkdir(validation_queries_dir) #creazione cartelle validation_query e test\n","      os.mkdir(test_dir)\n","      validation_list = os.listdir(validation_dir) #lista di file all'interno della cartella validation\n","      copied_id = [] #lista degli id che ho già copiato in validation list. All'inizio è vuota perchè non ho copiato nessuna immagine\n","      for file in validation_list:  #scorro la lista di file di validation\n","        id = file[0:4] #prelevo l'id del file corrente\n","        if id in copied_id: #se l'id è nell'array allora l'ho già copiato in validation_query quindi quest'altra immagine va copiata in test\n","          shutil.copy(validation_dir+\"/\"+file,test_dir+\"/\"+file) #copia file\n","        else:\n","        #se l'id non è presente nell'array allora devo copiare l'immagine in validation_query e inserire l'id nell'array dei già copiati\n","          shutil.copy(validation_dir+\"/\"+file,validation_queries_dir+\"/\"+file)\n","          copied_id.append(id)'''\n","\n"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1639663382994,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"ghq3W8EdTPvv"},"outputs":[],"source":["class CustomDataset(Dataset):\n","\n","    # STUDIARSI L'ESEMPIO GIA' FATTO QUI: -> https://pytorch.org/tutorials/beginner/basics/data_tutorial.html , sezione \"Creating a Custom Dataset for your files\"\n","\n","    # override:\n","    # csvfile e imgfolder sono stringhe con la directory corrispettiva\n","    def __init__(self, imgfolder, train, csvfile=None):\n","\n","        # creazione dizionario\n","        self.train = train\n","        self.imgfolder = imgfolder\n","        self.dictionary = {}\n","        self.img_list = os.listdir(imgfolder)\n","        # numero di file all'interno della cartella contenente le immagini\n","        self.size = len(self.img_list)\n","        if csvfile != None:\n","            with open(csvfile, mode='r') as annotations_train:\n","                reader = csv.reader(annotations_train, delimiter=',')\n","                # Salto prima riga per non avere i nomi degli attributi nel dizionario\n","                next(reader, None)\n","                for row in reader:\n","                    # Questo modo ritorna una sublist nel range di index indicato senza contare però l'ultimo elemento!\n","                    up = row[11:19]\n","                    down = row[19:]\n","                    # tengo per la lista solo i primi 10 attributi e quelli relativi ai colori up e down li compatto in due attributi distinti che concateno poi\n","                    id = int(row[0])\n","\n","                    row = row[1:11]\n","\n","                    if '2' in up:  # per le label decido che il loro valore è il corrispettivo dell'index+1. Se nessun valore è ugale a '2' allora ho un multicolor che indico con un valore = all'ultima label+1\n","                        # concateno attributo upcolor\n","                        row.append(up.index('2')+1)\n","                    else:\n","                        row.append(9)\n","                    if '2' in down:\n","                        # concateno attributo downcolor\n","                        row.append(down.index('2')+1)\n","                    else:\n","                        row.append(10)\n","\n","                    for label in row:\n","                        # converto in intero le label degli attributi\n","                        row[row.index(label)] = int(label) - 1\n","                    self.dictionary[id] = row\n","\n","    # override:\n","    # return the element at index idx:\n","    def __getitem__(self, idx):\n","        transform = list()\n","        # transform.append(T.ConvertImageDtype(torch.float))\n","        transform.append(T.Normalize(\n","            mean=[0.485, 0.456, 0.406],\n","            std=[0.229, 0.224, 0.225]),\n","        )\n","        transform.append(T.Resize((256, 128)))\n","\n","        img = Image.open(self.imgfolder+\"/\"+self.img_list[idx])\n","        img = T.ToTensor()(img)\n","\n","        transform = T.Compose(transform)\n","        img = transform(img)\n","        if self.train == True:\n","            transform = list()\n","\n","            transform.append(T.RandomRotation(5))\n","            transform.append(T.RandomCrop((256, 128), 10))\n","            transform.append(T.RandomHorizontalFlip())\n","            transform = T.Compose(transform)\n","            img = transform(img)\n","            # print(self.dictionary[int(self.img_list[idx][0:4])])\n","            return img, (torch.as_tensor(self.dictionary[int(self.img_list[idx][0:4])]))\n","        else:\n","            return img\n","    # override:\n","\n","    def __len__(self):\n","        # return the number of elements that compose the dataset:\n","        return self.size"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":26,"status":"ok","timestamp":1639663382995,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"kNrPlJ0g2yG8"},"outputs":[],"source":["def translate_attributes(attributes):\n","  translated_attributes = {}\n","  attributes_names = [\"age\",\"backpack\",\"bag\",\"handbag\",\"clothes\",\"down\",\"up\",\"hair\",\"hat\",\"gender\",\"upcolor\",\"downcolor\"] #traduttore\n","\n","  translator = [\n","                [\"young\", \"teenager\", \"adult\", \"old\"], #index: 0 attribute: age\n","                [\"no\", \"yes\"], #index: 1 attribute: backpack\n","                [\"no\", \"yes\"], #index: 2 attribute: bag\n","                [\"no\", \"yes\"], #index: 3 attribute: handbag\n","                [\"dress\", \"pants\"], #index: 4 attribute: clothes\n","                [\"long lower body clothing\", \"short\"], #index: 5 attribute: down\n","                [\"long sleeve short\", \"sleeve\"], #index: 6 attribute: up\n","                [\"short hair\", \"long hair\"], #index: 7 attribute: hair\n","                [\"no\", \"yes\"], #index: 8 attribute: hat\n","                [\"male\",\"female\"], #index: 9 attribute: gender\n","                [\"black\", \"white\", \"red\", \"purple\", \"yellow\", \"gray\", \"blue\", \"green\", \"multicolor\"], #index: 10 attribute: upcolor\n","                [\"black\", \"white\", \"pink\", \"purple\", \"yellow\", \"gray\", \"blue\", \"green\", \"brown\", \"multicolor\"], #index: 11 attribute: downcolor\n","  ]\n","  \n","  for i in range(len(attributes)):\n","    #le posizioni degli attributi coincidono coi due vettori e per ottenere la label tradotta è sufficente prenderne il valore-1 per ottenere \n","    #l'index corrispettivo nella lista di label tradotte\n","    translated_attributes[attributes_names[i]] = translator[i][attributes[i]-1] \n","  return translated_attributes"]},{"cell_type":"code","execution_count":27,"metadata":{"executionInfo":{"elapsed":24,"status":"ok","timestamp":1639663382996,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"p9kzqHqOSMH0"},"outputs":[],"source":["def get_data(batch_size, img_root):\n","\n","    # Load data:\n","    training_data = CustomDataset(\n","        img_root+\"train\", True, img_root+\"annotations_train.csv\")\n","    val_data = CustomDataset(img_root+\"validation\",\n","                             True, img_root+\"annotations_train.csv\")\n","    test_data = CustomDataset(img_root+\"test\", False)\n","    query_data = CustomDataset(img_root+\"queries\", False)\n","\n","    # Initialize dataloaders:\n","    train_loader = torch.utils.data.DataLoader(\n","        training_data, batch_size, shuffle=True, num_workers=0)\n","    val_loader = torch.utils.data.DataLoader(\n","        val_data, batch_size, shuffle=False, num_workers=0)\n","    test_loader = torch.utils.data.DataLoader(\n","        test_data, batch_size, shuffle=False, num_workers=0)\n","    query_loader = torch.utils.data.DataLoader(\n","        query_data, batch_size, shuffle=False, num_workers=0)\n","\n","    return train_loader, val_loader, test_loader, query_loader"]},{"cell_type":"markdown","metadata":{"id":"X5jRoWUzpJ-x"},"source":["**2) CNN implementation**\n","\n","NOTA: di tutta questa parte va aggiornato completamente il codice con le nostre scelte e reimplementati tutti i classificatori!!! (per task 1 e task 2)"]},{"cell_type":"code","execution_count":28,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1639663382997,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"FaKf3Bck6sOq"},"outputs":[],"source":["class Our_CNN(torch.nn.Module):\n","    # init override:\n","    def __init__(self, num_heads=num_classifiers, loss={'xent'}, **kwargs):\n","\n","        super(Our_CNN, self).__init__()\n","\n","        # load default resnet from pytorch:\n","        resnet = torchvision.models.resnet50(pretrained=True, progress=True)\n","        # save number of input features from last layer:\n","\n","        # cavo l'ultimo layer alla resnet\n","        self.backbone = torch.nn.Sequential(*list(resnet.children())[:-1])\n","\n","        self.fc = torch.nn.ModuleList()\n","\n","        self.fc.append(torch.nn.Linear(2048, 4))\n","        for i in range(1, 10):\n","            self.fc.append(torch.nn.Linear(2048, 2))\n","        self.fc.append(torch.nn.Linear(2048, 9))\n","        self.fc.append(torch.nn.Linear(2048, 10))\n","\n","    # forward pass:\n","    def forward(self, x):\n","        # forward though backbone portion of network:\n","\n","        x = self.backbone(x)\n","        x = x.flatten(1)\n","\n","        # put the output in (batch_size, input_dim) format and save as features:\n","        feats = x.view(x.shape[0], -1)\n","\n","        # loop through fc layers and store fwd pass in outputs list:\n","        outputs = []\n","        for fc in self.fc:\n","            outputs.append(fc(x))\n","\n","        # return both output list (task 1) and features (task 2):\n","        return outputs, feats\n"]},{"cell_type":"code","execution_count":29,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1639663382999,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"BMhUj_Rs6v8s"},"outputs":[],"source":["def cost_function(outputs, targets):\n","    loss = 0.0\n","    for i in range(len(outputs)):\n","        loss += F.cross_entropy(outputs[i], targets.t()[i])\n","    return loss"]},{"cell_type":"code","execution_count":30,"metadata":{"executionInfo":{"elapsed":516,"status":"ok","timestamp":1639663383494,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"bBtnyTAGszkh"},"outputs":[],"source":["#Optimizer:\n","#Da -> https://colab.research.google.com/drive/1oOKXtUUaACKG_P1SZO-PpfygP5_12dX7#scrollTo=FK8A9alWqYZ2 \n","\n","#Da aggiornare sulla base dei nostri classificatori.\n","def get_optimizer(model, lr, wd, momentum):\n","  \n","  return torch.optim.Adam(\n","        model.parameters(),\n","        lr=lr,\n","        weight_decay=wd)"]},{"cell_type":"code","execution_count":31,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1639663383495,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"wZY1hIns6zpm"},"outputs":[],"source":["#TRAIN & TEST FUNCTIONS:\n","#Da -> https://colab.research.google.com/drive/1oOKXtUUaACKG_P1SZO-PpfygP5_12dX7#scrollTo=FK8A9alWqYZ2 \n","\n","#Train function:\n","def train(net,data_loader,optimizer):\n","  samples = 0.\n","  cumulative_loss = 0.\n","  cumulative_accuracy = 0.\n","\n","  net.train() # Strictly needed if network contains layers which has different behaviours between train and test\n","  for batch_idx, (inputs, targets) in enumerate(data_loader):\n","    # Load data into GPU\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","    # Forward pass\n","    outputs,feats = net(inputs)\n","    loss = 0\n","\n","    loss = cost_function(outputs,targets)\n","\n","    #stats print:\n","    samples+=inputs.shape[0]\n","\n","    cumulative_loss += loss.item()\n","\n","    predicted = []\n","    for i in range(len(outputs)):\n","      predicted.append(outputs[i].max(1)[1])\n","      cumulative_accuracy += predicted[i].eq(targets.t()[i]).sum().item()\n","      \n","    # Backward pass\n","    loss.backward()\n","    \n","    # Update parameters\n","    optimizer.step()\n","    \n","    # Reset the optimizer\n","    optimizer.zero_grad()\n","  return cumulative_loss/samples, 100*cumulative_accuracy/(len(outputs)*samples)\n","\n","#Test function:\n","def test(net, data_loader):\n","  samples = 0.\n","  cumulative_loss = 0.\n","  cumulative_accuracy = 0.\n","\n","  net.eval() # Strictly needed if network contains layers which has different behaviours between train and test\n","  with torch.no_grad():\n","    for batch_idx, (inputs, targets) in enumerate(data_loader):\n","\n","      #print(\"batch_idx: \",batch_idx)\n","      # Load data into GPU\n","      inputs = inputs.to(device)\n","      targets = targets.to(device)\n","\n","      # Forward pass\n","      outputs,feats = net(inputs)\n","      \n","      # Apply the loss:\n","      loss = 0\n","      #for i in range(inputs.shape[0]):\n","       # layer_loss = cost_function(outputs[i], targets[i])\n","        # loss = loss + layer_loss\n","      loss = cost_function(outputs,targets)\n","      samples+=inputs.shape[0]\n","      cumulative_loss += loss.item() # Note: the .item() is needed to extract scalars from tensors\n","      predicted = []\n","      for i in range(len(outputs)):\n","        predicted.append(outputs[i].max(1)[1])\n","        cumulative_accuracy += predicted[i].eq(targets.t()[i]).sum().item()\n","\n","  return cumulative_loss/samples, 100*cumulative_accuracy/(len(outputs)*samples)"]},{"cell_type":"code","execution_count":32,"metadata":{"executionInfo":{"elapsed":14,"status":"ok","timestamp":1639663383496,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"urs7bAoxvs8c"},"outputs":[],"source":["#Funzione di esportazione file output per task 1 (\"classification_test.csv\" - vedi PDF assignment)"]},{"cell_type":"code","execution_count":33,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1639663383497,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"2M8b7XKVv2xl"},"outputs":[],"source":["#Funzione di esportazione file output per task 2 (\"reid_text.txt\" - vedi PDF assignment)"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9390029,"status":"ok","timestamp":1639672773515,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"3Dc6pe4BuhP0","outputId":"f444282e-2348-4563-c754-189210dd5cbb"},"outputs":[{"name":"stdout","output_type":"stream","text":["<_io.TextIOWrapper name='/content/Dataset/annotations_train.csv' mode='r' encoding='UTF-8'>\n","Moving 25% of training files in validation\n","Training files moved to validation\n","Tesla K80\n","Before training:\n","\t Training loss 0.19159, Training accuracy 46.87\n","\t Val loss 0.19205, Val accuracy 46.91\n","-----------------------------------------------------\n","Epoch: 1\n","\t Training loss 0.09549, Training accuracy 80.33\n","\t Val loss 0.11555, Val accuracy 78.04\n","-----------------------------------------------------\n","Epoch: 2\n","\t Training loss 0.07056, Training accuracy 85.52\n","\t Val loss 0.10659, Val accuracy 80.69\n","-----------------------------------------------------\n","Epoch: 3\n","\t Training loss 0.05844, Training accuracy 88.16\n","\t Val loss 0.11763, Val accuracy 80.89\n","-----------------------------------------------------\n","Epoch: 4\n","\t Training loss 0.04840, Training accuracy 90.14\n","\t Val loss 0.11966, Val accuracy 80.86\n","-----------------------------------------------------\n","Epoch: 5\n","\t Training loss 0.03996, Training accuracy 92.01\n","\t Val loss 0.11423, Val accuracy 80.15\n","-----------------------------------------------------\n","Epoch: 6\n","\t Training loss 0.03424, Training accuracy 93.18\n","\t Val loss 0.12946, Val accuracy 80.93\n","-----------------------------------------------------\n","Epoch: 7\n","\t Training loss 0.02750, Training accuracy 94.60\n","\t Val loss 0.12941, Val accuracy 81.88\n","-----------------------------------------------------\n","Epoch: 8\n","\t Training loss 0.02407, Training accuracy 95.34\n","\t Val loss 0.13500, Val accuracy 80.66\n","-----------------------------------------------------\n","Epoch: 9\n","\t Training loss 0.01892, Training accuracy 96.40\n","\t Val loss 0.15493, Val accuracy 80.26\n","-----------------------------------------------------\n","Epoch: 10\n","\t Training loss 0.01571, Training accuracy 97.00\n","\t Val loss 0.15151, Val accuracy 81.23\n","-----------------------------------------------------\n","Epoch: 11\n","\t Training loss 0.01468, Training accuracy 97.18\n","\t Val loss 0.16626, Val accuracy 79.49\n","-----------------------------------------------------\n","Epoch: 12\n","\t Training loss 0.01226, Training accuracy 97.66\n","\t Val loss 0.17027, Val accuracy 81.28\n","-----------------------------------------------------\n","Epoch: 13\n","\t Training loss 0.01072, Training accuracy 97.99\n","\t Val loss 0.17074, Val accuracy 81.37\n","-----------------------------------------------------\n","Epoch: 14\n","\t Training loss 0.00900, Training accuracy 98.35\n","\t Val loss 0.17323, Val accuracy 81.21\n","-----------------------------------------------------\n","Epoch: 15\n","\t Training loss 0.01021, Training accuracy 98.03\n","\t Val loss 0.18177, Val accuracy 80.50\n","-----------------------------------------------------\n","Epoch: 16\n","\t Training loss 0.01065, Training accuracy 98.04\n","\t Val loss 0.17411, Val accuracy 80.84\n","-----------------------------------------------------\n","Epoch: 17\n","\t Training loss 0.00606, Training accuracy 98.91\n","\t Val loss 0.18305, Val accuracy 81.31\n","-----------------------------------------------------\n","Epoch: 18\n","\t Training loss 0.00547, Training accuracy 99.01\n","\t Val loss 0.18887, Val accuracy 80.96\n","-----------------------------------------------------\n","Epoch: 19\n","\t Training loss 0.00646, Training accuracy 98.83\n","\t Val loss 0.18454, Val accuracy 81.30\n","-----------------------------------------------------\n","Epoch: 20\n","\t Training loss 0.00541, Training accuracy 99.03\n","\t Val loss 0.20847, Val accuracy 80.83\n","-----------------------------------------------------\n","Epoch: 21\n","\t Training loss 0.00663, Training accuracy 98.82\n","\t Val loss 0.19913, Val accuracy 80.73\n","-----------------------------------------------------\n","Epoch: 22\n","\t Training loss 0.00528, Training accuracy 99.04\n","\t Val loss 0.19724, Val accuracy 81.74\n","-----------------------------------------------------\n","Epoch: 23\n","\t Training loss 0.00496, Training accuracy 99.10\n","\t Val loss 0.20602, Val accuracy 81.16\n","-----------------------------------------------------\n","Epoch: 24\n","\t Training loss 0.00528, Training accuracy 99.00\n","\t Val loss 0.19959, Val accuracy 81.61\n","-----------------------------------------------------\n","Epoch: 25\n","\t Training loss 0.00531, Training accuracy 99.02\n","\t Val loss 0.20974, Val accuracy 80.41\n","-----------------------------------------------------\n","Epoch: 26\n","\t Training loss 0.00626, Training accuracy 98.86\n","\t Val loss 0.20149, Val accuracy 80.56\n","-----------------------------------------------------\n","Epoch: 27\n","\t Training loss 0.00356, Training accuracy 99.36\n","\t Val loss 0.22286, Val accuracy 80.80\n","-----------------------------------------------------\n","Epoch: 28\n","\t Training loss 0.00283, Training accuracy 99.49\n","\t Val loss 0.20328, Val accuracy 81.61\n","-----------------------------------------------------\n","Epoch: 29\n","\t Training loss 0.00335, Training accuracy 99.41\n","\t Val loss 0.21542, Val accuracy 79.93\n","-----------------------------------------------------\n","Epoch: 30\n","\t Training loss 0.00468, Training accuracy 99.15\n","\t Val loss 0.21441, Val accuracy 79.82\n","-----------------------------------------------------\n","Epoch: 31\n","\t Training loss 0.00489, Training accuracy 99.13\n","\t Val loss 0.21732, Val accuracy 81.29\n","-----------------------------------------------------\n","Epoch: 32\n","\t Training loss 0.00513, Training accuracy 99.08\n","\t Val loss 0.21447, Val accuracy 81.19\n","-----------------------------------------------------\n","Epoch: 33\n","\t Training loss 0.00368, Training accuracy 99.35\n","\t Val loss 0.21259, Val accuracy 81.10\n","-----------------------------------------------------\n","Epoch: 34\n","\t Training loss 0.00249, Training accuracy 99.57\n","\t Val loss 0.22704, Val accuracy 81.35\n","-----------------------------------------------------\n","Epoch: 35\n","\t Training loss 0.00236, Training accuracy 99.59\n","\t Val loss 0.22319, Val accuracy 81.22\n","-----------------------------------------------------\n","Epoch: 36\n","\t Training loss 0.00269, Training accuracy 99.54\n","\t Val loss 0.21569, Val accuracy 81.43\n","-----------------------------------------------------\n","Epoch: 37\n","\t Training loss 0.00383, Training accuracy 99.37\n","\t Val loss 0.23525, Val accuracy 80.67\n","-----------------------------------------------------\n","Epoch: 38\n","\t Training loss 0.00454, Training accuracy 99.17\n","\t Val loss 0.22603, Val accuracy 81.70\n","-----------------------------------------------------\n","Epoch: 39\n","\t Training loss 0.00473, Training accuracy 99.15\n","\t Val loss 0.22264, Val accuracy 81.39\n","-----------------------------------------------------\n","Epoch: 40\n","\t Training loss 0.00247, Training accuracy 99.57\n","\t Val loss 0.22383, Val accuracy 81.47\n","-----------------------------------------------------\n","Epoch: 41\n","\t Training loss 0.00211, Training accuracy 99.63\n","\t Val loss 0.22820, Val accuracy 80.50\n","-----------------------------------------------------\n","Epoch: 42\n","\t Training loss 0.00171, Training accuracy 99.71\n","\t Val loss 0.23072, Val accuracy 81.57\n","-----------------------------------------------------\n","Epoch: 43\n","\t Training loss 0.00154, Training accuracy 99.73\n","\t Val loss 0.25676, Val accuracy 81.58\n","-----------------------------------------------------\n","Epoch: 44\n","\t Training loss 0.00309, Training accuracy 99.47\n","\t Val loss 0.24267, Val accuracy 80.25\n","-----------------------------------------------------\n","Epoch: 45\n","\t Training loss 0.00462, Training accuracy 99.16\n","\t Val loss 0.25806, Val accuracy 80.12\n","-----------------------------------------------------\n","Epoch: 46\n","\t Training loss 0.00388, Training accuracy 99.30\n","\t Val loss 0.22313, Val accuracy 81.50\n","-----------------------------------------------------\n","Epoch: 47\n","\t Training loss 0.00209, Training accuracy 99.65\n","\t Val loss 0.22548, Val accuracy 81.92\n","-----------------------------------------------------\n","Epoch: 48\n","\t Training loss 0.00179, Training accuracy 99.68\n","\t Val loss 0.23840, Val accuracy 81.74\n","-----------------------------------------------------\n","Epoch: 49\n","\t Training loss 0.00177, Training accuracy 99.71\n","\t Val loss 0.22280, Val accuracy 81.74\n","-----------------------------------------------------\n","Epoch: 50\n","\t Training loss 0.00189, Training accuracy 99.67\n","\t Val loss 0.24331, Val accuracy 80.99\n","-----------------------------------------------------\n","After training:\n","\t Training loss 0.00167, Training accuracy 99.74\n","\t Val loss 0.24485, Val accuracy 80.94\n","-----------------------------------------------------\n"]}],"source":["#MAIN PER TASK 1\n","#Modificare da -> https://colab.research.google.com/drive/1oOKXtUUaACKG_P1SZO-PpfygP5_12dX7#scrollTo=FK8A9alWqYZ2 \n","#MAIN PER TASK 1\n","'''\n","Input arguments\n","  batch_size: Size of a mini-batch\n","  device: GPU where you want to train your network\n","  weight_decay: Weight decay co-efficient for regularization of weights\n","  momentum: Momentum for SGD optimizer\n","  epochs: Number of epochs for training the network\n","  num_classes: Number of classes in your dataset\n","  visualization_name: Name of the visualization folder\n","  img_root: The root folder of images\n","'''\n","\n","def main(batch_size=64, \n","         learning_rate=0.001, \n","         weight_decay=0.000001, \n","         momentum=0.9, \n","         epochs=50, \n","         num_classes=12, \n","         visualization_name='resnet50', \n","         img_root=localpath):\n","  \n","  dataset_preparation(img_root,img_root+\"annotations_train.csv\")#function that prepare the validation, query_validation and test folders\n","  writer = SummaryWriter(log_dir=\"runs/exp1\")\n","\n","  # Instantiates dataloaders\n","  train_loader, val_loader, test_loader, query_loader = get_data(batch_size=batch_size, img_root=img_root)\n","  \n","  # Instantiates the model\n","  print(torch.cuda.get_device_name(0))\n","  net = Our_CNN()\n","  net = net.to(device)\n","  \n","  # Instantiates the optimizer\n","  optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n","  \n","  # Instantiates the cost function\n","  #cost_function = get_cost_function()\n","\n","  print('Before training:')\n","  train_loss, train_accuracy = test(net, train_loader)\n","  val_loss, val_accuracy = test(net,val_loader)\n","\n","  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","  print('\\t Val loss {:.5f}, Val accuracy {:.2f}'.format(val_loss, val_accuracy))\n","  print('-----------------------------------------------------')\n","  \n","  # Add values to plots\n","  writer.add_scalar('Loss/train_loss', train_loss, 0)\n","  writer.add_scalar('Loss/val_loss', val_loss, 0)\n","  writer.add_scalar('Accuracy/train_accuracy', train_accuracy, 0)\n","  writer.add_scalar('Accuracy/val_accuracy', val_accuracy, 0)\n","\n","  for e in range(epochs):\n","    train_loss, train_accuracy = train(net, train_loader, optimizer)\n","    val_loss, val_accuracy = test(net, val_loader)\n","    print('Epoch: {:d}'.format(e+1))\n","    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","    print('\\t Val loss {:.5f}, Val accuracy {:.2f}'.format(val_loss, val_accuracy))\n","    print('-----------------------------------------------------')\n","    \n","    # Add values to plots\n","    writer.add_scalar('Loss/train_loss', train_loss, e + 1)\n","    writer.add_scalar('Loss/val_loss', val_loss, e + 1)\n","    writer.add_scalar('Accuracy/train_accuracy', train_accuracy, e + 1)\n","    writer.add_scalar('Accuracy/val_accuracy', val_accuracy, e + 1)\n","\n","  print('After training:')\n","  train_loss, train_accuracy = test(net, train_loader)\n","  val_loss, val_accuracy = test(net, val_loader)\n","\n","  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n","  print('\\t Val loss {:.5f}, Val accuracy {:.2f}'.format(val_loss, val_accuracy))\n","  print('-----------------------------------------------------')\n","\n","  # Closes the logger\n","  writer.close()\n","\n","main()\n"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":15,"status":"ok","timestamp":1639672773517,"user":{"displayName":"Davide Dalla Stella","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"07042227837747022347"},"user_tz":-60},"id":"iL7OAb0Iu5G2"},"outputs":[],"source":["#MAIN PER TASK 2\n","#Ripetere da sopra e poi???"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"MAIN_CODE_UNITO.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
