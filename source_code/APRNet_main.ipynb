{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sg9k_BBLMS93"
      },
      "source": [
        "# **Deep Learning Project**\n",
        "\n",
        "**Eliana Battisti (223701) - Davide Dalla Stella () - Francesco Trono (221723)**\n",
        "\n",
        "*University of Trento*\n",
        "\n",
        "A.Y. 2020/2021 - Deep Learning Course"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RaBW1U_WwcXf"
      },
      "source": [
        "Click to open & run in Colab:\n",
        "\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ftrono/DL_Project/blob/main/source_code/APRNet_main.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EbSOUkq2cmbH",
        "outputId": "ebbd3725-5f5a-4621-819d-6d7c57154eef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.11.0.dev20211216+cu102)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0.dev20211216+cu102)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.10.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision) (1.19.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision) (2.10)\n"
          ]
        }
      ],
      "source": [
        "!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu102/torch_nightly.html -U"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0KPK4NeNMS4N"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import csv\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import collections\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "from sklearn.preprocessing import MultiLabelBinarizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xw8kNODXwcXj"
      },
      "source": [
        "**0) Set working directory & global variables**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vGAgnXzlwcXj"
      },
      "outputs": [],
      "source": [
        "#Set FLAG to 1 only if you want to create the git clone and the Datasets from scratch\n",
        "FLAG = 1\n",
        "\n",
        "if flag == 1:\n",
        "    !git clone https://github.com/ftrono/DL_Project.git\n",
        "    % cd DL_Project\n",
        "    print(\"Git cloned.\")\n",
        "    #unzip dataset:\n",
        "    !unzip 'dataset.zip' -d './Dataset' >/dev/null\n",
        "    print(\"Dataset unzipped.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GYBV9XAnR3Qt"
      },
      "outputs": [],
      "source": [
        "#Global variables:\n",
        "num_classifiers = 12\n",
        "device = \"cuda:0\"\n",
        "#device = \"cpu\"\n",
        "datapath = \"./Dataset/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upUeC5MRMz5N"
      },
      "source": [
        "**1) Dataset preparation**\n",
        "\n",
        "1.1) Dataset split (training / validation)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HljEsNz5PND1"
      },
      "outputs": [],
      "source": [
        "#Dataset split\n",
        "def dataset_preparation(img_root, csv_dir):\n",
        "\n",
        "    # PART 1\n",
        "    validation_dir = img_root+\"validation\"\n",
        "    train_dir = img_root+\"train\"\n",
        "    n_id = -1 #id counter (starts from -1 to exclude heading)\n",
        "\n",
        "    #validation folder must be created & populated only once:\n",
        "    if not os.path.isdir(validation_dir):\n",
        "        os.mkdir(validation_dir)\n",
        "        #open annotation csv\n",
        "        with open(csv_dir) as annotations_train:\n",
        "            #print(annotations_train)\n",
        "            #count and sum ids with a for cycle\n",
        "            n_id += sum(1 for row in annotations_train)\n",
        "\n",
        "        #split: training 75%, validation 25%\n",
        "        to_move = n_id // 4\n",
        "\n",
        "        #move images to validation folder:\n",
        "        print(\"Moving 25% of training files to validation\")\n",
        "        for i in range(0, to_move):\n",
        "            #get updated list of filenames in the train directory (do it at each new loop)\n",
        "            train_list = os.listdir(train_dir)\n",
        "            #get person ID from first filename (first 4 chars)\n",
        "            id_to_move = train_list[0][0:4]\n",
        "            #print(\"id to move: \", id_to_move)\n",
        "            #move all files with that ID:\n",
        "            for files in train_list:\n",
        "                if files.startswith(id_to_move):\n",
        "                    shutil.move(train_dir+\"/\"+files, validation_dir+\"/\"+files)\n",
        "                    #print(\"Moved: \",train_dir+\"/\"+files, \"to: \",validation_dir+\"/\"+files)\n",
        "\n",
        "        print(\"Validation files moved to val folder.\")\n",
        "    else:\n",
        "        print(\"Validation already created.\")\n",
        "\n",
        "\n",
        "    # PART 2\n",
        "    '''\n",
        "    validation_queries_dir = img_root+ \"/validation_queries\"\n",
        "    test_dir = img_root + \"/test\"\n",
        "\n",
        "    if not os.path.isdir(validation_queries_dir): #Se una delle cartelle non esiste allora assumo che non ne esista nessuna\n",
        "      if not os.path.isdir(test_dir):\n",
        "        os.mkdir(validation_queries_dir) #creazione cartelle validation_query e test\n",
        "        os.mkdir(test_dir)\n",
        "        validation_list = os.listdir(validation_dir) #lista di file all'interno della cartella validation\n",
        "        copied_id = [] #lista degli id che ho già copiato in validation list. All'inizio è vuota perchè non ho copiato nessuna immagine\n",
        "        for file in validation_list:  #scorro la lista di file di validation\n",
        "          id = file[0:4] #prelevo l'id del file corrente\n",
        "          if id in copied_id: #se l'id è nell'array allora l'ho già copiato in validation_query quindi quest'altra immagine va copiata in test\n",
        "            shutil.copy(validation_dir+\"/\"+file,test_dir+\"/\"+file) #copia file\n",
        "          else:\n",
        "          #se l'id non è presente nell'array allora devo copiare l'immagine in validation_query e inserire l'id nell'array dei già copiati\n",
        "            shutil.copy(validation_dir+\"/\"+file,validation_queries_dir+\"/\"+file)\n",
        "            copied_id.append(id)\n",
        "    '''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D0vsad4YwcXq"
      },
      "source": [
        "1.2) Dataset class (stores the samples and their corresponding labels):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghq3W8EdTPvv"
      },
      "outputs": [],
      "source": [
        "class CustomDataset(Dataset):\n",
        "\n",
        "    #override:\n",
        "    #init dataset class:\n",
        "    #(Note: csvfile and imgfolder are directory strings)\n",
        "    def __init__(self, imgfolder, train, csvfile=None):\n",
        "\n",
        "        #init annotations dictionary:\n",
        "        self.train = train\n",
        "        self.imgfolder = imgfolder\n",
        "        self.dictionary = {}\n",
        "        #number of files in the directory\n",
        "        self.img_list = os.listdir(imgfolder)\n",
        "        self.size = len(self.img_list)\n",
        "        #if annotations available:\n",
        "        if csvfile != None:\n",
        "            with open(csvfile, mode='r') as annotations_train:\n",
        "                reader = csv.reader(annotations_train, delimiter=',')\n",
        "                #skip header row\n",
        "                next(reader, None)\n",
        "                for row in reader:\n",
        "                    #group upcolor values (8 labels):\n",
        "                    up = row[11:19]\n",
        "                    #group downcolor values (9 labels):\n",
        "                    down = row[19:]\n",
        "                    #get id:\n",
        "                    id = int(row[0])\n",
        "\n",
        "                    #init attributes concatenation with first 10 attributes:\n",
        "                    row = row[1:11]\n",
        "\n",
        "                    #append upcolor value to concatenation (set as label index+1):\n",
        "                    #NOTE: if no original value in upcolors is '2', the label must be 'multicolor' (index = 9):\n",
        "                    if '2' in up:\n",
        "                        row.append(up.index('2')+1)\n",
        "                    else:\n",
        "                        row.append(9)\n",
        "\n",
        "                    #append downcolor value to concatenation (same as for upcolor. Multicolor index here will be 10):   \n",
        "                    if '2' in down:\n",
        "                        row.append(down.index('2')+1)\n",
        "                    else:\n",
        "                        row.append(10)\n",
        "\n",
        "                    #convert all labels to int - 1:\n",
        "                    for label in row:\n",
        "                        row[row.index(label)] = int(label) - 1\n",
        "\n",
        "                    #append to annotations dictionary:\n",
        "                    self.dictionary[id] = row\n",
        "\n",
        "    #override:\n",
        "    #return the element at index idx:\n",
        "    def __getitem__(self, idx):\n",
        "        #standard transformations for the data loader:\n",
        "        transform = list()\n",
        "        #normalize with ImageNet mean:\n",
        "        transform.append(T.Normalize(\n",
        "            mean=[0.485, 0.456, 0.406],\n",
        "            std=[0.229, 0.224, 0.225])\n",
        "        )\n",
        "        #resize:\n",
        "        transform.append(T.Resize((256, 128)))\n",
        "\n",
        "        #get image and convert to tensor, then apply standard transformations:\n",
        "        img = Image.open(self.imgfolder+\"/\"+self.img_list[idx])\n",
        "        img = T.ToTensor()(img)\n",
        "        transform = T.Compose(transform)\n",
        "        img = transform(img)\n",
        "\n",
        "        #if training mode:    \n",
        "        if self.train == True:\n",
        "            #apply additional transformations for the train loader:\n",
        "            transform = list()\n",
        "            transform.append(T.RandomRotation(5))\n",
        "            transform.append(T.RandomCrop((256, 128), 10))\n",
        "            transform.append(T.RandomHorizontalFlip())\n",
        "            transform = T.Compose(transform)\n",
        "            img = transform(img)\n",
        "\n",
        "            #return image & labels:\n",
        "            #print(self.dictionary[int(self.img_list[idx][0:4])])\n",
        "            return img, (torch.as_tensor(self.dictionary[int(self.img_list[idx][0:4])]))\n",
        "        else:\n",
        "            #return only image:\n",
        "            return img\n",
        "    \n",
        "    #override:\n",
        "    #return the number of elements that compose the dataset:\n",
        "    def __len__(self):\n",
        "        return self.size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0R3ZS9DwcXs"
      },
      "source": [
        "1.3) Dataloader class (wraps an iterable around the Dataset to enable easy access to the samples):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9kzqHqOSMH0"
      },
      "outputs": [],
      "source": [
        "def get_data(batch_size, img_root):\n",
        "\n",
        "    #load data:\n",
        "    training_data = CustomDataset(img_root+\"train\", True, img_root+\"annotations_train.csv\")\n",
        "    val_data = CustomDataset(img_root+\"validation\", True, img_root+\"annotations_train.csv\")\n",
        "    test_data = CustomDataset(img_root+\"test\", False)\n",
        "    query_data = CustomDataset(img_root+\"queries\", False)\n",
        "\n",
        "    #initialize dataloaders:\n",
        "    train_loader = torch.utils.data.DataLoader(training_data, batch_size, shuffle=True, num_workers=4)\n",
        "    val_loader = torch.utils.data.DataLoader(val_data, batch_size, shuffle=False, num_workers=4)\n",
        "    test_loader = torch.utils.data.DataLoader(test_data, batch_size, shuffle=False, num_workers=4)\n",
        "    query_loader = torch.utils.data.DataLoader(query_data, batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "    return train_loader, val_loader, test_loader, query_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cGGFVUKawcXt"
      },
      "source": [
        "1.4) Attributes translator (from integers to human-readable strings):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kNrPlJ0g2yG8"
      },
      "outputs": [],
      "source": [
        "def translate_attributes(attributes):\n",
        "  translated_attributes = {}\n",
        "  attributes_names = [\"age\",\"backpack\",\"bag\",\"handbag\",\"clothes\",\"down\",\"up\",\"hair\",\"hat\",\"gender\",\"upcolor\",\"downcolor\"] #translator\n",
        "\n",
        "  translator = [\n",
        "                [\"young\", \"teenager\", \"adult\", \"old\"], #index: 0 attribute: age\n",
        "                [\"no\", \"yes\"], #index: 1 attribute: backpack\n",
        "                [\"no\", \"yes\"], #index: 2 attribute: bag\n",
        "                [\"no\", \"yes\"], #index: 3 attribute: handbag\n",
        "                [\"dress\", \"pants\"], #index: 4 attribute: clothes\n",
        "                [\"long lower body clothing\", \"short\"], #index: 5 attribute: down\n",
        "                [\"long sleeve short\", \"sleeve\"], #index: 6 attribute: up\n",
        "                [\"short hair\", \"long hair\"], #index: 7 attribute: hair\n",
        "                [\"no\", \"yes\"], #index: 8 attribute: hat\n",
        "                [\"male\",\"female\"], #index: 9 attribute: gender\n",
        "                [\"black\", \"white\", \"red\", \"purple\", \"yellow\", \"gray\", \"blue\", \"green\", \"multicolor\"], #index: 10 attribute: upcolor\n",
        "                [\"black\", \"white\", \"pink\", \"purple\", \"yellow\", \"gray\", \"blue\", \"green\", \"brown\", \"multicolor\"], #index: 11 attribute: downcolor\n",
        "  ]\n",
        "  \n",
        "  #attributes positions are the same in the 2 vectors: \n",
        "  #to translate a label, simply do value-1 to get its index in the translated labels list:\n",
        "  for i in range(len(attributes)):\n",
        "    translated_attributes[attributes_names[i]] = translator[i][attributes[i]-1] \n",
        "  return translated_attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5jRoWUzpJ-x"
      },
      "source": [
        "**2) CNN implementation**\n",
        "\n",
        "2.1) Net:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FaKf3Bck6sOq"
      },
      "outputs": [],
      "source": [
        "class Our_CNN(torch.nn.Module):\n",
        "\n",
        "    #init override:\n",
        "    def __init__(self, num_heads=num_classifiers, loss={'xent'}, **kwargs):\n",
        "        super(Our_CNN, self).__init__()\n",
        "\n",
        "        #load default ResNet from PyTorch:\n",
        "        resnet = torchvision.models.resnet50(pretrained=True, progress=True)\n",
        "        #save number of input features from last layer:\n",
        "        last_infeats = resnet.fc.in_features\n",
        "\n",
        "        #remove last FC layer:\n",
        "        self.backbone = torch.nn.Sequential(*list(resnet.children())[:-1])\n",
        "\n",
        "        #append list of classifiers (one for each attribute):\n",
        "        self.fc = torch.nn.ModuleList()\n",
        "\n",
        "        self.fc.append(torch.nn.Linear(last_infeats, 4)) #age classifier\n",
        "        for i in range(1, 10):\n",
        "            self.fc.append(torch.nn.Linear(last_infeats, 2)) #binary classifiers\n",
        "        self.fc.append(torch.nn.Linear(last_infeats, 9)) #upcolor classifier\n",
        "        self.fc.append(torch.nn.Linear(last_infeats, 10)) #downcolor classifier\n",
        "\n",
        "\n",
        "    # forward pass:\n",
        "    def forward(self, x):\n",
        "        #forward though backbone portion of network:\n",
        "        x = self.backbone(x)\n",
        "        x = x.flatten(1)\n",
        "\n",
        "        #put the output in (batch_size, input_dim) format and save as features:\n",
        "        feats = x.view(x.shape[0], -1)\n",
        "\n",
        "        #loop through classifiers and store fwd pass in outputs list:\n",
        "        outputs = []\n",
        "        for fc in self.fc:\n",
        "            outputs.append(fc(x))\n",
        "\n",
        "        #return both output list (task 1) and features (task 2):\n",
        "        return outputs, feats"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PyygSEGwcXv"
      },
      "source": [
        "2.2) Loss function (total loss = sum of individual cross-entropy loss for each attribute classifier):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMhUj_Rs6v8s"
      },
      "outputs": [],
      "source": [
        "def cost_function(outputs, targets):\n",
        "    loss = 0.0\n",
        "    for i in range(len(outputs)):\n",
        "        loss += F.cross_entropy(outputs[i], targets.t()[i])\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwgeY7s8wcXw"
      },
      "source": [
        "2.3) Optimizer:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBtnyTAGszkh"
      },
      "outputs": [],
      "source": [
        "def get_optimizer(model, lr, wd, momentum):\n",
        "  return torch.optim.Adam(\n",
        "        model.parameters(),\n",
        "        lr=lr,\n",
        "        weight_decay=wd)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdGKpmjpwcXx"
      },
      "source": [
        "2.4) Train & test functions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZY1hIns6zpm"
      },
      "outputs": [],
      "source": [
        "#a) Train function:\n",
        "def train(net,data_loader,optimizer):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  #training mode:\n",
        "  net.train()\n",
        "  for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "    #load data into GPU:\n",
        "    inputs = inputs.to(device)\n",
        "    targets = targets.to(device)\n",
        "    #forward pass:\n",
        "    outputs, feats = net(inputs)\n",
        "\n",
        "    #get loss:\n",
        "    loss = 0\n",
        "    loss = cost_function(outputs,targets)\n",
        "\n",
        "    #stats print:\n",
        "    samples+=inputs.shape[0]\n",
        "    cumulative_loss += loss.item() #note: the .item() is needed to extract scalars from tensors\n",
        "    predicted = []\n",
        "    for i in range(len(outputs)):\n",
        "      predicted.append(outputs[i].max(1)[1])\n",
        "      cumulative_accuracy += predicted[i].eq(targets.t()[i]).sum().item()\n",
        "      \n",
        "    #backpropagate:\n",
        "    loss.backward()\n",
        "    \n",
        "    #update parameters:\n",
        "    optimizer.step()\n",
        "    \n",
        "    #reset the optimizer:\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "  return cumulative_loss/samples, 100*cumulative_accuracy/(len(outputs)*samples)\n",
        "\n",
        "\n",
        "#b) Test function:\n",
        "def test(net, data_loader):\n",
        "  samples = 0.\n",
        "  cumulative_loss = 0.\n",
        "  cumulative_accuracy = 0.\n",
        "\n",
        "  #evaluation mode:\n",
        "  net.eval()\n",
        "  with torch.no_grad():\n",
        "    for batch_idx, (inputs, targets) in enumerate(data_loader):\n",
        "      #print(\"batch_idx: \",batch_idx)\n",
        "      \n",
        "      #load data into GPU:\n",
        "      inputs = inputs.to(device)\n",
        "      targets = targets.to(device)\n",
        "\n",
        "      #forward pass:\n",
        "      outputs,feats = net(inputs)\n",
        "      \n",
        "      #get loss:\n",
        "      loss = 0\n",
        "      loss = cost_function(outputs,targets)\n",
        "\n",
        "      #stats print:\n",
        "      samples+=inputs.shape[0]\n",
        "      cumulative_loss += loss.item() \n",
        "      predicted = []\n",
        "      for i in range(len(outputs)):\n",
        "        predicted.append(outputs[i].max(1)[1])\n",
        "        cumulative_accuracy += predicted[i].eq(targets.t()[i]).sum().item()\n",
        "\n",
        "  return cumulative_loss/samples, 100*cumulative_accuracy/(len(outputs)*samples)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urs7bAoxvs8c"
      },
      "outputs": [],
      "source": [
        "#Funzione di esportazione file output per task 1 (\"classification_test.csv\" - vedi PDF assignment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2M8b7XKVv2xl"
      },
      "outputs": [],
      "source": [
        "#Funzione di esportazione file output per task 2 (\"reid_text.txt\" - vedi PDF assignment)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Ngzty6wcXz"
      },
      "source": [
        "**3) Main**\n",
        "\n",
        "3.1) Main function:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Task 1:\n",
        "'''\n",
        "Input arguments\n",
        "  batch_size: Size of a mini-batch\n",
        "  device: GPU where you want to train your network\n",
        "  weight_decay: Weight decay co-efficient for regularization of weights\n",
        "  momentum: Momentum for SGD optimizer\n",
        "  epochs: Number of epochs for training the network\n",
        "  num_classes: Number of classes in your dataset\n",
        "  visualization_name: Name of the visualization folder\n",
        "  img_root: The root folder of images\n",
        "'''\n",
        "\n",
        "def main(batch_size=64, \n",
        "         learning_rate=0.001, \n",
        "         weight_decay=0.000001, \n",
        "         momentum=0.9, \n",
        "         epochs=50, \n",
        "         num_classes=12, \n",
        "         visualization_name='resnet50', \n",
        "         img_root=datapath):\n",
        "  \n",
        "  #prepare the validation, query_validation and test folders:\n",
        "  dataset_preparation(img_root,img_root+\"annotations_train.csv\")\n",
        "\n",
        "  #logger:\n",
        "  writer = SummaryWriter(log_dir=\"./Output/exp1\")\n",
        "\n",
        "  #instantiate dataloaders:\n",
        "  train_loader, val_loader, test_loader, query_loader = get_data(batch_size=batch_size, img_root=img_root)\n",
        "  \n",
        "  #instantiate the network:\n",
        "  print(torch.cuda.get_device_name(0))\n",
        "  net = Our_CNN()\n",
        "  net = net.to(device)\n",
        "  \n",
        "  #instantiate the optimizer:\n",
        "  optimizer = get_optimizer(net, learning_rate, weight_decay, momentum)\n",
        "\n",
        "  print('Before training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader)\n",
        "  val_loss, val_accuracy = test(net,val_loader)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Val loss {:.5f}, Val accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "  \n",
        "  #add values to plots:\n",
        "  writer.add_scalar('Loss/train_loss', train_loss, 0)\n",
        "  writer.add_scalar('Loss/val_loss', val_loss, 0)\n",
        "  writer.add_scalar('Accuracy/train_accuracy', train_accuracy, 0)\n",
        "  writer.add_scalar('Accuracy/val_accuracy', val_accuracy, 0)\n",
        "\n",
        "  #epochs:\n",
        "  for e in range(epochs):\n",
        "    train_loss, train_accuracy = train(net, train_loader, optimizer) #train\n",
        "    val_loss, val_accuracy = test(net, val_loader) #test\n",
        "    print('Epoch: {:d}'.format(e+1))\n",
        "    print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "    print('\\t Val loss {:.5f}, Val accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "    print('-----------------------------------------------------')\n",
        "    \n",
        "    #add values to plots:\n",
        "    writer.add_scalar('Loss/train_loss', train_loss, e + 1)\n",
        "    writer.add_scalar('Loss/val_loss', val_loss, e + 1)\n",
        "    writer.add_scalar('Accuracy/train_accuracy', train_accuracy, e + 1)\n",
        "    writer.add_scalar('Accuracy/val_accuracy', val_accuracy, e + 1)\n",
        "\n",
        "  #test:\n",
        "  print('After training:')\n",
        "  train_loss, train_accuracy = test(net, train_loader)\n",
        "  val_loss, val_accuracy = test(net, val_loader)\n",
        "\n",
        "  print('\\t Training loss {:.5f}, Training accuracy {:.2f}'.format(train_loss, train_accuracy))\n",
        "  print('\\t Val loss {:.5f}, Val accuracy {:.2f}'.format(val_loss, val_accuracy))\n",
        "  print('-----------------------------------------------------')\n",
        "\n",
        "  #closes the logger:\n",
        "  writer.close()"
      ],
      "metadata": {
        "id": "xOqRc9bOzVzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.2) Reset runs directory & load Tensorboard:"
      ],
      "metadata": {
        "id": "pIeqcHAZzFDb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "runs = \".Output/runs\"\n",
        "! rm -r runs\n",
        "\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "metadata": {
        "id": "u6diS8eTzLbB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.3) Execute:"
      ],
      "metadata": {
        "id": "2v725liczMrP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Dc6pe4BuhP0",
        "outputId": "f444282e-2348-4563-c754-189210dd5cbb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<_io.TextIOWrapper name='/content/Dataset/annotations_train.csv' mode='r' encoding='UTF-8'>\n",
            "Moving 25% of training files in validation\n",
            "Training files moved to validation\n",
            "Tesla K80\n",
            "Before training:\n",
            "\t Training loss 0.19159, Training accuracy 46.87\n",
            "\t Val loss 0.19205, Val accuracy 46.91\n",
            "-----------------------------------------------------\n",
            "Epoch: 1\n",
            "\t Training loss 0.09549, Training accuracy 80.33\n",
            "\t Val loss 0.11555, Val accuracy 78.04\n",
            "-----------------------------------------------------\n",
            "Epoch: 2\n",
            "\t Training loss 0.07056, Training accuracy 85.52\n",
            "\t Val loss 0.10659, Val accuracy 80.69\n",
            "-----------------------------------------------------\n",
            "Epoch: 3\n",
            "\t Training loss 0.05844, Training accuracy 88.16\n",
            "\t Val loss 0.11763, Val accuracy 80.89\n",
            "-----------------------------------------------------\n",
            "Epoch: 4\n",
            "\t Training loss 0.04840, Training accuracy 90.14\n",
            "\t Val loss 0.11966, Val accuracy 80.86\n",
            "-----------------------------------------------------\n",
            "Epoch: 5\n",
            "\t Training loss 0.03996, Training accuracy 92.01\n",
            "\t Val loss 0.11423, Val accuracy 80.15\n",
            "-----------------------------------------------------\n",
            "Epoch: 6\n",
            "\t Training loss 0.03424, Training accuracy 93.18\n",
            "\t Val loss 0.12946, Val accuracy 80.93\n",
            "-----------------------------------------------------\n",
            "Epoch: 7\n",
            "\t Training loss 0.02750, Training accuracy 94.60\n",
            "\t Val loss 0.12941, Val accuracy 81.88\n",
            "-----------------------------------------------------\n",
            "Epoch: 8\n",
            "\t Training loss 0.02407, Training accuracy 95.34\n",
            "\t Val loss 0.13500, Val accuracy 80.66\n",
            "-----------------------------------------------------\n",
            "Epoch: 9\n",
            "\t Training loss 0.01892, Training accuracy 96.40\n",
            "\t Val loss 0.15493, Val accuracy 80.26\n",
            "-----------------------------------------------------\n",
            "Epoch: 10\n",
            "\t Training loss 0.01571, Training accuracy 97.00\n",
            "\t Val loss 0.15151, Val accuracy 81.23\n",
            "-----------------------------------------------------\n",
            "Epoch: 11\n",
            "\t Training loss 0.01468, Training accuracy 97.18\n",
            "\t Val loss 0.16626, Val accuracy 79.49\n",
            "-----------------------------------------------------\n",
            "Epoch: 12\n",
            "\t Training loss 0.01226, Training accuracy 97.66\n",
            "\t Val loss 0.17027, Val accuracy 81.28\n",
            "-----------------------------------------------------\n",
            "Epoch: 13\n",
            "\t Training loss 0.01072, Training accuracy 97.99\n",
            "\t Val loss 0.17074, Val accuracy 81.37\n",
            "-----------------------------------------------------\n",
            "Epoch: 14\n",
            "\t Training loss 0.00900, Training accuracy 98.35\n",
            "\t Val loss 0.17323, Val accuracy 81.21\n",
            "-----------------------------------------------------\n",
            "Epoch: 15\n",
            "\t Training loss 0.01021, Training accuracy 98.03\n",
            "\t Val loss 0.18177, Val accuracy 80.50\n",
            "-----------------------------------------------------\n",
            "Epoch: 16\n",
            "\t Training loss 0.01065, Training accuracy 98.04\n",
            "\t Val loss 0.17411, Val accuracy 80.84\n",
            "-----------------------------------------------------\n",
            "Epoch: 17\n",
            "\t Training loss 0.00606, Training accuracy 98.91\n",
            "\t Val loss 0.18305, Val accuracy 81.31\n",
            "-----------------------------------------------------\n",
            "Epoch: 18\n",
            "\t Training loss 0.00547, Training accuracy 99.01\n",
            "\t Val loss 0.18887, Val accuracy 80.96\n",
            "-----------------------------------------------------\n",
            "Epoch: 19\n",
            "\t Training loss 0.00646, Training accuracy 98.83\n",
            "\t Val loss 0.18454, Val accuracy 81.30\n",
            "-----------------------------------------------------\n",
            "Epoch: 20\n",
            "\t Training loss 0.00541, Training accuracy 99.03\n",
            "\t Val loss 0.20847, Val accuracy 80.83\n",
            "-----------------------------------------------------\n",
            "Epoch: 21\n",
            "\t Training loss 0.00663, Training accuracy 98.82\n",
            "\t Val loss 0.19913, Val accuracy 80.73\n",
            "-----------------------------------------------------\n",
            "Epoch: 22\n",
            "\t Training loss 0.00528, Training accuracy 99.04\n",
            "\t Val loss 0.19724, Val accuracy 81.74\n",
            "-----------------------------------------------------\n",
            "Epoch: 23\n",
            "\t Training loss 0.00496, Training accuracy 99.10\n",
            "\t Val loss 0.20602, Val accuracy 81.16\n",
            "-----------------------------------------------------\n",
            "Epoch: 24\n",
            "\t Training loss 0.00528, Training accuracy 99.00\n",
            "\t Val loss 0.19959, Val accuracy 81.61\n",
            "-----------------------------------------------------\n",
            "Epoch: 25\n",
            "\t Training loss 0.00531, Training accuracy 99.02\n",
            "\t Val loss 0.20974, Val accuracy 80.41\n",
            "-----------------------------------------------------\n",
            "Epoch: 26\n",
            "\t Training loss 0.00626, Training accuracy 98.86\n",
            "\t Val loss 0.20149, Val accuracy 80.56\n",
            "-----------------------------------------------------\n",
            "Epoch: 27\n",
            "\t Training loss 0.00356, Training accuracy 99.36\n",
            "\t Val loss 0.22286, Val accuracy 80.80\n",
            "-----------------------------------------------------\n",
            "Epoch: 28\n",
            "\t Training loss 0.00283, Training accuracy 99.49\n",
            "\t Val loss 0.20328, Val accuracy 81.61\n",
            "-----------------------------------------------------\n",
            "Epoch: 29\n",
            "\t Training loss 0.00335, Training accuracy 99.41\n",
            "\t Val loss 0.21542, Val accuracy 79.93\n",
            "-----------------------------------------------------\n",
            "Epoch: 30\n",
            "\t Training loss 0.00468, Training accuracy 99.15\n",
            "\t Val loss 0.21441, Val accuracy 79.82\n",
            "-----------------------------------------------------\n",
            "Epoch: 31\n",
            "\t Training loss 0.00489, Training accuracy 99.13\n",
            "\t Val loss 0.21732, Val accuracy 81.29\n",
            "-----------------------------------------------------\n",
            "Epoch: 32\n",
            "\t Training loss 0.00513, Training accuracy 99.08\n",
            "\t Val loss 0.21447, Val accuracy 81.19\n",
            "-----------------------------------------------------\n",
            "Epoch: 33\n",
            "\t Training loss 0.00368, Training accuracy 99.35\n",
            "\t Val loss 0.21259, Val accuracy 81.10\n",
            "-----------------------------------------------------\n",
            "Epoch: 34\n",
            "\t Training loss 0.00249, Training accuracy 99.57\n",
            "\t Val loss 0.22704, Val accuracy 81.35\n",
            "-----------------------------------------------------\n",
            "Epoch: 35\n",
            "\t Training loss 0.00236, Training accuracy 99.59\n",
            "\t Val loss 0.22319, Val accuracy 81.22\n",
            "-----------------------------------------------------\n",
            "Epoch: 36\n",
            "\t Training loss 0.00269, Training accuracy 99.54\n",
            "\t Val loss 0.21569, Val accuracy 81.43\n",
            "-----------------------------------------------------\n",
            "Epoch: 37\n",
            "\t Training loss 0.00383, Training accuracy 99.37\n",
            "\t Val loss 0.23525, Val accuracy 80.67\n",
            "-----------------------------------------------------\n",
            "Epoch: 38\n",
            "\t Training loss 0.00454, Training accuracy 99.17\n",
            "\t Val loss 0.22603, Val accuracy 81.70\n",
            "-----------------------------------------------------\n",
            "Epoch: 39\n",
            "\t Training loss 0.00473, Training accuracy 99.15\n",
            "\t Val loss 0.22264, Val accuracy 81.39\n",
            "-----------------------------------------------------\n",
            "Epoch: 40\n",
            "\t Training loss 0.00247, Training accuracy 99.57\n",
            "\t Val loss 0.22383, Val accuracy 81.47\n",
            "-----------------------------------------------------\n",
            "Epoch: 41\n",
            "\t Training loss 0.00211, Training accuracy 99.63\n",
            "\t Val loss 0.22820, Val accuracy 80.50\n",
            "-----------------------------------------------------\n",
            "Epoch: 42\n",
            "\t Training loss 0.00171, Training accuracy 99.71\n",
            "\t Val loss 0.23072, Val accuracy 81.57\n",
            "-----------------------------------------------------\n",
            "Epoch: 43\n",
            "\t Training loss 0.00154, Training accuracy 99.73\n",
            "\t Val loss 0.25676, Val accuracy 81.58\n",
            "-----------------------------------------------------\n",
            "Epoch: 44\n",
            "\t Training loss 0.00309, Training accuracy 99.47\n",
            "\t Val loss 0.24267, Val accuracy 80.25\n",
            "-----------------------------------------------------\n",
            "Epoch: 45\n",
            "\t Training loss 0.00462, Training accuracy 99.16\n",
            "\t Val loss 0.25806, Val accuracy 80.12\n",
            "-----------------------------------------------------\n",
            "Epoch: 46\n",
            "\t Training loss 0.00388, Training accuracy 99.30\n",
            "\t Val loss 0.22313, Val accuracy 81.50\n",
            "-----------------------------------------------------\n",
            "Epoch: 47\n",
            "\t Training loss 0.00209, Training accuracy 99.65\n",
            "\t Val loss 0.22548, Val accuracy 81.92\n",
            "-----------------------------------------------------\n",
            "Epoch: 48\n",
            "\t Training loss 0.00179, Training accuracy 99.68\n",
            "\t Val loss 0.23840, Val accuracy 81.74\n",
            "-----------------------------------------------------\n",
            "Epoch: 49\n",
            "\t Training loss 0.00177, Training accuracy 99.71\n",
            "\t Val loss 0.22280, Val accuracy 81.74\n",
            "-----------------------------------------------------\n",
            "Epoch: 50\n",
            "\t Training loss 0.00189, Training accuracy 99.67\n",
            "\t Val loss 0.24331, Val accuracy 80.99\n",
            "-----------------------------------------------------\n",
            "After training:\n",
            "\t Training loss 0.00167, Training accuracy 99.74\n",
            "\t Val loss 0.24485, Val accuracy 80.94\n",
            "-----------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iL7OAb0Iu5G2"
      },
      "outputs": [],
      "source": [
        "#MAIN PER TASK 2\n",
        "#Ripetere da sopra e poi???"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "APRNet_main.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}